# View the average RMSE over all folds
mean(RMSE(modelPred, saratoga_test$price))
##Medium Model
lm_medium = lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
rmse(lm_medium, saratoga_test)
##See Above, section obselete
## Improved Model
lm_improved = lm(price ~ . - bathrooms - pctCollege - fireplaces + newConstruction*age + rooms*bedrooms + fireplaces*bedrooms + lotSize*landValue, data = saratoga_test)
rmse(lm_improved, saratoga_test)
##Standardizing variables
##changing newConstruction to numeric
saratoga_train$newConstruction = as.numeric(saratoga_train$newConstruction)
saratoga_test$newConstruction = as.numeric(saratoga_test$newConstruction)
##Standardizing training
strain_stand <-
saratoga_train %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##StandardizingTesting
stest_stand <-
saratoga_test %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##model for KNN
##Model Attempt
model2 <- train(price ~ bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand,
method = "kknn",
trControl = train_control)
predictions <- predict(model2, stest_stand)
mean(RMSE(predictions, stest_stand$price))
##This is not correct - does not include CV
set.seed(123)
## Attempt for loop
k_vec= c(2:346)
knnk = list()
output = list()
rmse_vec = c()
## for loop trim = 350
for (i in 2:length(k_vec)){
knnk[[i]] = knnreg(price~bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand, k =  k_vec[i])
output[i] = stest_stand %>%
mutate(Price_Pred = predict(knnk[[i]], stest_stand))
##sclass350_test = sclass350_test %>%
## mutate(Price_pred = predict(knnk, sclass350_test))
rmse_vec[i] = modelr::rmse(knnk[[i]], stest_stand)
}
k_vec
rmse_vec
plot(k_vec, rmse_vec)
output
my_data = data.frame(k_vec, rmse_vec)
my_data
my_data = na.omit(my_data)
min(my_data$rmse_vec)
which.min(my_data$rmse_vec)
my_data
##2
##data wrangling
ger = read_csv("Data/german_credit.csv")
library(dplyr)
default_probabilities <- ger %>%
group_by(history) %>%
summarise(default_prob = mean(Default))
##2 Bar Graph
library(ggplot2)
ggplot(default_probabilities, aes(x = history, y = default_prob, fill = history)) +
geom_bar(stat = "identity") +
xlab("Credit History") +
ylab("Default Probability") +
ggtitle("Default Probability by Credit History")
##2 model
m1 = glm(Default ~ duration + amount + installment + age + history + purpose + foreign,
data = ger,
family = binomial())
summary(m1)
hotels_dev = read_csv("Data/hotels_dev.csv")
hotels_val = read.csv("Data/hotels_val.csv")
hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_train = training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)
m1_hotels_dev = lm(children ~ market_segment + adults + customer_type + is_repeated_guest, data = hotels_dev_train)
m2_hotels_dev = lm(children ~ . - arrival_date, data = hotels_dev_train)
#For our model we used a stepwise selection model using AIC
m3_hotels_dev = stepAIC(m2_hotels_dev, direction = "both",
trace = FALSE, k = log(36000))
rmse(m1_hotels_dev, data = hotels_dev_test)
rmse(m2_hotels_dev, data = hotels_dev_test)
rmse(m3_hotels_dev, data = hotels_dev_test)
# While our RMSE test did not show significan improvement, the stability.simplicity of the resulting model is a welcomed improvement.
phat_test_children1 = predict(m1_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children1 = ifelse(phat_test_children1 > 0.5, 1, 0)
confusion_m1 = table(y = hotels_dev_test$children, yhat = yhat_test_children1)
confusion_m1
phat_test_children2 = predict(m2_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children2 = ifelse(phat_test_children2 > 0.5, 1, 0)
confusion_m2 = table(y = hotels_dev_test$children, yhat = yhat_test_children2)
confusion_m2
phat_test_children3 = predict(m3_hotels_dev, hotels_dev_test)
yhat_test_children3 = ifelse(phat_test_children3 > 0.5, 1, 0)
confusion_m3 = table(y = hotels_dev_test$children, yhat = yhat_test_children3)
confusion_m3
table(hotels_dev_test$children)
m1_accuracy = sum(diag(confusion_m1))/sum(confusion_m1)
m2_accuracy = sum(diag(confusion_m2))/sum(confusion_m2)
m3_accuracy = sum(diag(confusion_m3))/sum(confusion_m3)
null_accuracy = 8276/(8276+724)
m1_accuracy
m2_accuracy
m3_accuracy
null_accuracy
# Absolute Improvement
m1_absimpr = m1_accuracy - null_accuracy
m2_absimpr = m2_accuracy - null_accuracy
m3_absimpr = m3_accuracy - null_accuracy
m1_absimpr
m2_absimpr
m3_absimpr
# Lift
m1_lift = m1_accuracy/null_accuracy
m2_lift = m2_accuracy/null_accuracy
m3_lift = m3_accuracy/null_accuracy
m1_lift
m2_lift
m3_lift
m3_pred_values <- predict(m3_hotels_dev, hotels_val, type = "response")
m3_pred_data <- prediction(m3_pred_values, hotels_val$children)
roc_data <- performance(m3_pred_data, measure="tpr", x.measure="fpr")
plot(roc_data, main = "ROC Curve for Model 3")
k_folds = 20
hotels_val = hotels_val %>%
mutate(fold_number = rep(1:k_folds, length = nrow(hotels_val)) %>% sample())
actual_children <- list()
expected_children <- list()
difference_children <- list()
for (x in 1:20) {
fold <- hotels_val %>%
filter(fold_number == x)
phat <- predict(m3_hotels_dev, fold)
expected_children[[x]] <- round(sum(phat), 2)
actual_children [[x]] <- sum(fold$children)
difference_children[[x]] <- round(expected_children[[x]] - actual_children[[x]], 2)
}
fold_id = list(seq(1, 20, by=1))
predict_table = tibble("FOLD_ID" = unlist(fold_id), "EXPECTED" = unlist(expected_children), "ACTUAL" = unlist(actual_children), "DIFFERENCE" = unlist(difference_children))
predict_table
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(caret)
library(purrr)
library(readr)
library(dplyr)
library(MASS)
library(ROCR)
##2 Bar Graph
library(ggplot2)
ggplot(default_probabilities, aes(x = history, y = default_prob, fill = history)) +
geom_bar(stat = "identity") +
xlab("Credit History") +
ylab("Default Probability") +
ggtitle("Default Probability by Credit History")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(caret)
library(purrr)
library(readr)
library(dplyr)
library(MASS)
library(ROCR)
##Data Entry/Train Test Split
set.seed(80)
data(SaratogaHouses)
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
##Improved Model wih CV
##CV split
# Define the number of folds
num_folds <- 10
# Create a training control object with repeated cross-validation
train_control <- trainControl(method = "repeatedcv",
number = num_folds,
repeats = 100)
# Train a model using the training control object
model <- train(price ~ . - bathrooms - pctCollege - fireplaces + newConstruction*age + rooms*bedrooms + fireplaces*bedrooms + lotSize*landValue, data = saratoga_train,
method = "lm",
trControl = train_control)
modelPred = predict(model, saratoga_test)
# View the average RMSE over all folds
mean(RMSE(modelPred, saratoga_test$price))
##Medium Model
lm_medium = lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
rmse(lm_medium, saratoga_test)
##See Above, section obselete
## Improved Model
lm_improved = lm(price ~ . - bathrooms - pctCollege - fireplaces + newConstruction*age + rooms*bedrooms + fireplaces*bedrooms + lotSize*landValue, data = saratoga_test)
rmse(lm_improved, saratoga_test)
##Standardizing variables
##changing newConstruction to numeric
saratoga_train$newConstruction = as.numeric(saratoga_train$newConstruction)
saratoga_test$newConstruction = as.numeric(saratoga_test$newConstruction)
##Standardizing training
strain_stand <-
saratoga_train %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##StandardizingTesting
stest_stand <-
saratoga_test %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##model for KNN
##Model Attempt
model2 <- train(price ~ bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand,
method = "kknn",
trControl = train_control)
predictions <- predict(model2, stest_stand)
mean(RMSE(predictions, stest_stand$price))
##This is not correct - does not include CV
set.seed(123)
## Attempt for loop
k_vec= c(2:346)
knnk = list()
output = list()
rmse_vec = c()
## for loop trim = 350
for (i in 2:length(k_vec)){
knnk[[i]] = knnreg(price~bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand, k =  k_vec[i])
output[i] = stest_stand %>%
mutate(Price_Pred = predict(knnk[[i]], stest_stand))
##sclass350_test = sclass350_test %>%
## mutate(Price_pred = predict(knnk, sclass350_test))
rmse_vec[i] = modelr::rmse(knnk[[i]], stest_stand)
}
k_vec
rmse_vec
plot(k_vec, rmse_vec)
output
my_data = data.frame(k_vec, rmse_vec)
my_data
my_data = na.omit(my_data)
min(my_data$rmse_vec)
which.min(my_data$rmse_vec)
my_data
##2
##data wrangling
ger = read_csv("Data/german_credit.csv")
library(dplyr)
default_probabilities <- ger %>%
group_by(history) %>%
summarise(default_prob = mean(Default))
##2 Bar Graph
library(ggplot2)
ggplot(default_probabilities, aes(x = history, y = default_prob, fill = history)) +
geom_bar(stat = "identity") +
xlab("Credit History") +
ylab("Default Probability") +
ggtitle("Default Probability by Credit History")
##2 model
m1 = glm(Default ~ duration + amount + installment + age + history + purpose + foreign,
data = ger,
family = binomial())
summary(m1)
hotels_dev = read_csv("Data/hotels_dev.csv")
hotels_val = read.csv("Data/hotels_val.csv")
hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_train = training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)
m1_hotels_dev = lm(children ~ market_segment + adults + customer_type + is_repeated_guest, data = hotels_dev_train)
m2_hotels_dev = lm(children ~ . - arrival_date, data = hotels_dev_train)
#For our model we used a stepwise selection model using AIC
m3_hotels_dev = stepAIC(m2_hotels_dev, direction = "both",
trace = FALSE, k = log(36000))
rmse(m1_hotels_dev, data = hotels_dev_test)
rmse(m2_hotels_dev, data = hotels_dev_test)
rmse(m3_hotels_dev, data = hotels_dev_test)
# While our RMSE test did not show significan improvement, the stability.simplicity of the resulting model is a welcomed improvement.
phat_test_children1 = predict(m1_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children1 = ifelse(phat_test_children1 > 0.5, 1, 0)
confusion_m1 = table(y = hotels_dev_test$children, yhat = yhat_test_children1)
confusion_m1
phat_test_children2 = predict(m2_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children2 = ifelse(phat_test_children2 > 0.5, 1, 0)
confusion_m2 = table(y = hotels_dev_test$children, yhat = yhat_test_children2)
confusion_m2
phat_test_children3 = predict(m3_hotels_dev, hotels_dev_test)
yhat_test_children3 = ifelse(phat_test_children3 > 0.5, 1, 0)
confusion_m3 = table(y = hotels_dev_test$children, yhat = yhat_test_children3)
confusion_m3
table(hotels_dev_test$children)
m1_accuracy = sum(diag(confusion_m1))/sum(confusion_m1)
m2_accuracy = sum(diag(confusion_m2))/sum(confusion_m2)
m3_accuracy = sum(diag(confusion_m3))/sum(confusion_m3)
null_accuracy = 8276/(8276+724)
m1_accuracy
m2_accuracy
m3_accuracy
null_accuracy
# Absolute Improvement
m1_absimpr = m1_accuracy - null_accuracy
m2_absimpr = m2_accuracy - null_accuracy
m3_absimpr = m3_accuracy - null_accuracy
m1_absimpr
m2_absimpr
m3_absimpr
# Lift
m1_lift = m1_accuracy/null_accuracy
m2_lift = m2_accuracy/null_accuracy
m3_lift = m3_accuracy/null_accuracy
m1_lift
m2_lift
m3_lift
m3_pred_values <- predict(m3_hotels_dev, hotels_val, type = "response")
m3_pred_data <- prediction(m3_pred_values, hotels_val$children)
roc_data <- performance(m3_pred_data, measure="tpr", x.measure="fpr")
plot(roc_data, main = "ROC Curve for Model 3")
k_folds = 20
hotels_val = hotels_val %>%
mutate(fold_number = rep(1:k_folds, length = nrow(hotels_val)) %>% sample())
actual_children <- list()
expected_children <- list()
difference_children <- list()
for (x in 1:20) {
fold <- hotels_val %>%
filter(fold_number == x)
phat <- predict(m3_hotels_dev, fold)
expected_children[[x]] <- round(sum(phat), 2)
actual_children [[x]] <- sum(fold$children)
difference_children[[x]] <- round(expected_children[[x]] - actual_children[[x]], 2)
}
fold_id = list(seq(1, 20, by=1))
predict_table = tibble("FOLD_ID" = unlist(fold_id), "EXPECTED" = unlist(expected_children), "ACTUAL" = unlist(actual_children), "DIFFERENCE" = unlist(difference_children))
predict_table
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(caret)
library(purrr)
library(readr)
library(dplyr)
library(MASS)
library(ROCR)
##Data Entry/Train Test Split
set.seed(80)
data(SaratogaHouses)
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
##Improved Model wih CV
##CV split
# Define the number of folds
num_folds <- 10
# Create a training control object with repeated cross-validation
train_control <- trainControl(method = "repeatedcv",
number = num_folds,
repeats = 100)
# Train a model using the training control object
model <- train(price ~ . - bathrooms - pctCollege - fireplaces + newConstruction*age + rooms*bedrooms + fireplaces*bedrooms + lotSize*landValue, data = saratoga_train,
method = "lm",
trControl = train_control)
modelPred = predict(model, saratoga_test)
# View the average RMSE over all folds
mean(RMSE(modelPred, saratoga_test$price))
##Medium Model
lm_medium = lm(price ~ . - pctCollege - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
rmse(lm_medium, saratoga_test)
##See Above, section obselete
## Improved Model
lm_improved = lm(price ~ . - bathrooms - pctCollege - fireplaces + newConstruction*age + rooms*bedrooms + fireplaces*bedrooms + lotSize*landValue, data = saratoga_test)
rmse(lm_improved, saratoga_test)
##Standardizing variables
##changing newConstruction to numeric
saratoga_train$newConstruction = as.numeric(saratoga_train$newConstruction)
saratoga_test$newConstruction = as.numeric(saratoga_test$newConstruction)
##Standardizing training
strain_stand <-
saratoga_train %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##StandardizingTesting
stest_stand <-
saratoga_test %>%
mutate(bath_s = scale(bathrooms), pctCollege_s = scale(pctCollege), fireplaces_s= scale(fireplaces), newConstruction_s = scale(newConstruction), age_s = scale(age),rooms_s = scale(rooms), bedrooms_s = scale(bedrooms), lotSize_s = scale(lotSize),landValue_s = scale(landValue))
##model for KNN
##Model Attempt
model2 <- train(price ~ bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand,
method = "kknn",
trControl = train_control)
predictions <- predict(model2, stest_stand)
mean(RMSE(predictions, stest_stand$price))
##This is not correct - does not include CV
set.seed(123)
## Attempt for loop
k_vec= c(2:346)
knnk = list()
output = list()
rmse_vec = c()
## for loop trim = 350
for (i in 2:length(k_vec)){
knnk[[i]] = knnreg(price~bath_s + pctCollege_s + fireplaces_s + newConstruction_s + age_s + rooms_s + bedrooms_s +lotSize_s +landValue_s, data = strain_stand, k =  k_vec[i])
output[i] = stest_stand %>%
mutate(Price_Pred = predict(knnk[[i]], stest_stand))
##sclass350_test = sclass350_test %>%
## mutate(Price_pred = predict(knnk, sclass350_test))
rmse_vec[i] = modelr::rmse(knnk[[i]], stest_stand)
}
k_vec
rmse_vec
plot(k_vec, rmse_vec)
output
my_data = data.frame(k_vec, rmse_vec)
my_data
my_data = na.omit(my_data)
min(my_data$rmse_vec)
which.min(my_data$rmse_vec)
my_data
##2
##data wrangling
ger = read_csv("Data/german_credit.csv")
library(dplyr)
default_probabilities <- ger %>%
group_by(history) %>%
summarise(default_prob = mean(Default))
##2 Bar Graph
library(ggplot2)
ggplot(default_probabilities, aes(x = history, y = default_prob, fill = history)) +
geom_bar(stat = "identity") +
xlab("Credit History") +
ylab("Default Probability") +
ggtitle("Default Probability by Credit History")
##2 model
m1 = glm(Default ~ duration + amount + installment + age + history + purpose + foreign,
data = ger,
family = binomial())
summary(m1)
hotels_dev = read_csv("Data/hotels_dev.csv")
hotels_val = read.csv("Data/hotels_val.csv")
hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_train = training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)
m1_hotels_dev = lm(children ~ market_segment + adults + customer_type + is_repeated_guest, data = hotels_dev_train)
m2_hotels_dev = lm(children ~ . - arrival_date, data = hotels_dev_train)
#For our model we used a stepwise selection model using AIC
m3_hotels_dev = stepAIC(m2_hotels_dev, direction = "both",
trace = FALSE, k = log(36000))
rmse(m1_hotels_dev, data = hotels_dev_test)
rmse(m2_hotels_dev, data = hotels_dev_test)
rmse(m3_hotels_dev, data = hotels_dev_test)
# While our RMSE test did not show significan improvement, the stability.simplicity of the resulting model is a welcomed improvement.
phat_test_children1 = predict(m1_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children1 = ifelse(phat_test_children1 > 0.5, 1, 0)
confusion_m1 = table(y = hotels_dev_test$children, yhat = yhat_test_children1)
confusion_m1
phat_test_children2 = predict(m2_hotels_dev, hotels_dev_test, type = 'response')
yhat_test_children2 = ifelse(phat_test_children2 > 0.5, 1, 0)
confusion_m2 = table(y = hotels_dev_test$children, yhat = yhat_test_children2)
confusion_m2
phat_test_children3 = predict(m3_hotels_dev, hotels_dev_test)
yhat_test_children3 = ifelse(phat_test_children3 > 0.5, 1, 0)
confusion_m3 = table(y = hotels_dev_test$children, yhat = yhat_test_children3)
confusion_m3
table(hotels_dev_test$children)
m1_accuracy = sum(diag(confusion_m1))/sum(confusion_m1)
m2_accuracy = sum(diag(confusion_m2))/sum(confusion_m2)
m3_accuracy = sum(diag(confusion_m3))/sum(confusion_m3)
null_accuracy = 8276/(8276+724)
m1_accuracy
m2_accuracy
m3_accuracy
null_accuracy
# Absolute Improvement
m1_absimpr = m1_accuracy - null_accuracy
m2_absimpr = m2_accuracy - null_accuracy
m3_absimpr = m3_accuracy - null_accuracy
m1_absimpr
m2_absimpr
m3_absimpr
# Lift
m1_lift = m1_accuracy/null_accuracy
m2_lift = m2_accuracy/null_accuracy
m3_lift = m3_accuracy/null_accuracy
m1_lift
m2_lift
m3_lift
m3_pred_values <- predict(m3_hotels_dev, hotels_val, type = "response")
m3_pred_data <- prediction(m3_pred_values, hotels_val$children)
roc_data <- performance(m3_pred_data, measure="tpr", x.measure="fpr")
plot(roc_data, main = "ROC Curve for Model 3")
k_folds = 20
hotels_val = hotels_val %>%
mutate(fold_number = rep(1:k_folds, length = nrow(hotels_val)) %>% sample())
actual_children <- list()
expected_children <- list()
difference_children <- list()
for (x in 1:20) {
fold <- hotels_val %>%
filter(fold_number == x)
phat <- predict(m3_hotels_dev, fold)
expected_children[[x]] <- round(sum(phat), 2)
actual_children [[x]] <- sum(fold$children)
difference_children[[x]] <- round(expected_children[[x]] - actual_children[[x]], 2)
}
fold_id = list(seq(1, 20, by=1))
predict_table = tibble("FOLD_ID" = unlist(fold_id), "EXPECTED" = unlist(expected_children), "ACTUAL" = unlist(actual_children), "DIFFERENCE" = unlist(difference_children))
predict_table
unlink("HW2_cache", recursive = TRUE)
knit_with_parameters("~/Library/CloudStorage/Dropbox/UT/2022_Spring/ECO 395M_DATA MINING/GitHub/HW2/R/HW2.Rmd")
